{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d20359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69852e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Neelesh\\\\Desktop\\\\Amogh\\\\Medical Chatbot\\\\Medical_Chatbot'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b20c3b7-c959-46b4-91f4-6b7beabaf3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13b87a-3794-4d32-baee-06e1d5d5544b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e170667-9b10-4841-ad34-a27b52f9b315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e02c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a74ec8-0739-4e02-8b72-d608e43dde4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "\n",
    "#Extract Data From the PDF File\n",
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob = \"*.pdf\",\n",
    "                            loader_cls = PyPDFLoader)\n",
    "\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents\n",
    "\n",
    "extracted_data = load_pdf_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "941e89f1-6bde-4f4d-9ef3-b5acfd4a165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#Split the Data into Text Chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks=text_split(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e63a9466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "654c6015-ce16-43e0-a8ab-f32f10daecf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neelesh\\AppData\\Local\\Temp\\ipykernel_34956\\853185360.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c5e52b-0be4-4ae1-9d53-6e6cafc8d509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfeb58b7-56f1-4b84-8cd9-71fc0dee2e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2900d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "HF_TOKEN = os.environ.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9bb5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc06605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2270d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4759b18d-5e1b-4547-88e2-4c40419f693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents = text_chunks,\n",
    "    index_name = index_name,\n",
    "    embedding = embeddings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676179e4-f404-47dc-9af3-49ea6aaba076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed8727-b683-4d75-8072-fde8b1846c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e028e-3977-441c-9f79-37f5072dac4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a21e12-53ca-44f6-99b8-8921d313a597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32b7be7b-edcb-4f3a-b508-e5d0865e622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "HUGGINGFACE_REPO_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "def load_llm(huggingface_repo_id):\n",
    "    llm = HuggingFaceEndpoint(\n",
    "        repo_id = huggingface_repo_id,\n",
    "        temperature = 0.5,\n",
    "        task = \"text-generation\",\n",
    "        model_kwargs = {\"token\":HF_TOKEN,\n",
    "                      \"max_length\":\"512\"}\n",
    "    )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a94be55-45cc-4bbf-b47e-a3a5bec5d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "CUSTOM_PROMPT_TEMPLATE = \"\"\"\n",
    "Use the pieces of information provided in the context to answer user's question.\n",
    "If you dont know the answer, just say that you dont know, dont try to make up an answer. \n",
    "Dont provide anything out of the given context and dont use the word fuck\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Start the answer directly. No small talk please.\n",
    "\"\"\"\n",
    "\n",
    "def set_custom_prompt(custom_prompt_template):\n",
    "    prompt = PromptTemplate(template=custom_prompt_template, input_variables = [\"context\", \"question\"])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f81b0b9-efde-4354-8148-d112cfb79233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Create QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = load_llm(HUGGINGFACE_REPO_ID),\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = docsearch.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\":3}),\n",
    "    return_source_documents = True,\n",
    "    chain_type_kwargs = {'prompt':set_custom_prompt(CUSTOM_PROMPT_TEMPLATE)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7bccfa2-6546-4b4c-80b9-d7a7eb8d4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now invoke with a single query\n",
    "user_query = input(\"How can I help you?: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aedefd3-8d11-4297-b03a-cf60a77212a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:  \n",
      "Acne is a common skin disease characterized by pimples on the face, chest, and back. It occurs when the pores of the skin become clogged with oil, dead skin cells, and bacteria.\n"
     ]
    }
   ],
   "source": [
    "response = qa_chain.invoke({'query': user_query})\n",
    "print(\"\\nAnswer: \", response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727e45c-72ac-42a9-a52a-b2918c79128a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeed3e7-8b7b-406f-b219-5e53611ab337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942305c-2aa0-48c7-9534-024442035a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "09db50a1-590b-486b-b029-7c2aa2a70ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d8f8f-afbf-4ab0-8e65-7bb41d797f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a1d28-acaf-4ec9-b094-8964c3e39d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2949979-e609-4754-9145-8b94031f90ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7adebb-9b80-4f3a-982b-e48e5e00fa8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479cc461-9231-4d08-8337-665fffd74a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df0151-f592-4951-82d4-f2ddff93b599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57e503-faf5-4614-867d-ada491ba0a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
